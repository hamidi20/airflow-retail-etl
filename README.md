# ğŸš€ Airflow Retail ETL Pipeline

## ğŸ“Œ Project Overview

This project demonstrates an end-to-end ETL pipeline built using **Apache Airflow** and **PostgreSQL**.
The architecture separates the **Master (source) database** and **Warehouse (analytics) database** using **PostgreSQL Foreign Data Wrapper (FDW)**.
The pipeline extracts retail transaction data from a CSV file, loads it into a master database, and transforms it into a structured warehouse table ready for analytics.

---

## ğŸ—ï¸ Architecture

CSV File  
â¬‡  
Master Database (`retail_master`)  
â¬‡ (PostgreSQL FDW)  
Warehouse Database  
â¬‡  
`retail_sales` (Fact Table)

---

## ğŸ”„ ETL Workflow

### 1ï¸âƒ£ Extract & Load (PythonOperator)

- ğŸ“‚ Read CSV file (`retail-dataset.csv`)
- ğŸ—‘ï¸ Truncate `retail_master`
- âš¡ Bulk load using PostgreSQL `COPY`
- ğŸ•’ Handle date format with:
  
  ```sql
  SET datestyle TO 'ISO, DMY';
  ```
---

### 2ï¸âƒ£ Transform (PostgresOperator)

- ğŸ”— Connect to Warehouse DB
- ğŸ“Š Query `retail_master` via FDW
- ğŸ§¹ Apply data transformation:
  - Handle NULL values using `COALESCE`
  - Filter by date range
  - Create calculated column:
  ```sql
  totalamount = quantity * unitprice
  ```
- ğŸ’¾ Insert results into `retail_sales`

---

## ğŸ› ï¸ Technologies Used

- ğŸ Python 3
- ğŸŒªï¸ Apache Airflow 2.x
- ğŸ˜ PostgreSQL
- ğŸ”Œ PostgreSQL FDW
- ğŸ³ Docker & Docker Compose
- ğŸ—‚ï¸ Git & GitHub

---

## ğŸ‘¨â€ğŸ’» Author

**Hamidi**  
Data Engineer  
Specializing in ETL, Data Warehousing, and Data Orchestration
